{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmhHYix09fiu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "mydata = load_dataset('valhalla/emoji-dataset')\n",
    "keywords = ['face','christmas','superhero','supervillian','mage','vampire','monkey','elf','juggling',\n",
    "            'boy','girl','adult','person','man','woman','male','female','worker','scientist','technologist',\n",
    "            'singer','artist','pilot','astronaut','firefighter','police','sleuth','construction']\n",
    "# keywords = ['face']\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [1.5, 1.50]\n",
    "\n",
    "mydata = load_dataset('valhalla/emoji-dataset')\n",
    "print(len(mydata['train']))\n",
    "total_obs = len(mydata['train'])\n",
    "data = np.zeros([total_obs,3,64,64],dtype='float32')\n",
    "for i in range(total_obs):\n",
    "    print(i)\n",
    "    im = mydata['train'][i]['image']\n",
    "    title = mydata['train'][i]['text']\n",
    "    if title.find(keywords[0]) > -1:\n",
    "        plt.imshow(im)\n",
    "        print(title)\n",
    "        plt.show()\n",
    "\n",
    "        im = im.resize((64,64),Image.LANCZOS)\n",
    "        title = \"lower resolution\"\n",
    "        plt.imshow(im)\n",
    "        print(title)\n",
    "        plt.show()\n",
    "        pix = im.load()\n",
    "        for x in range(im.size[0]):\n",
    "            for y in range(im.size[1]):\n",
    "                for c in range(3):\n",
    "                    data[i,c,x,y] = float(pix[x,y][c]) / 255.0\n",
    "                    \n",
    "# keep only samples that have any nonzero pixel\n",
    "mask = (data != 0).any(axis=(1,2,3))\n",
    "data_nz = data[mask]\n",
    "print(data.shape, \"â†’\", data_nz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(arr: np.ndarray, sigma=0.02):\n",
    "    noise = np.random.normal(0.0, sigma, size=arr.shape).astype(np.float32)\n",
    "    out = arr + noise\n",
    "    return out.clip(0.0, 1.0)\n",
    "\n",
    "sigma = 0.02\n",
    "outs = [data_nz.astype(np.float32, copy=False)]\n",
    "for _ in range(5):  # +5 noisy copies = 6x total with original\n",
    "    outs.append(add_gaussian_noise(data_nz, sigma))\n",
    "augmented_data = np.concatenate(outs, axis=0)\n",
    "print(augmented_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Root directory for dataset\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(augmented_data))  # each item -> (img,)\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.001\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(2,1,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # input is ``(nc) x 64 x 64``\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf) x 32 x 32``\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*2) x 16 x 16``\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(ndf * 8, nz, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return 0.5*(self.decoder(self.encoder(input))+1)\n",
    "\n",
    "# Create the Discriminator\n",
    "netAutoEncoder = AutoEncoder().to(device)\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "# like this: ``to mean=0, stdev=0.2``.\n",
    "netAutoEncoder.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netAutoEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ``MSELoss`` function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(netAutoEncoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        netAutoEncoder.zero_grad()\n",
    "        \n",
    "        x = data[0].to(device)\n",
    "        x_out = netAutoEncoder(x)\n",
    "        \n",
    "        err = criterion(x_out, x)\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss: %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     err.item()))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        losses.append(err.item())\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(losses,label=\"Train\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))[0]\n",
    "out_batch = netAutoEncoder(real_batch)\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch.cpu()[:64], padding=2, normalize=True).cpu(),(2,1,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Reconstructed Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(out_batch.cpu()[:64], padding=2, normalize=True).cpu(),(2,1,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- describe your dataset and the steps that you used to create it,\n",
    "- provide a summary of your architecture\n",
    "- discuss and explain your design choices,\n",
    "- list hyper-parameters used in the model,\n",
    "- plot learning curves for training and validation loss as a function of training epochs,\n",
    "- provide the final average error of your autoencoder on your test set,\n",
    "- provide a side-by-side example of 5 input and output images, and\n",
    "- discuss any decisions or observations that you find relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))[0]\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "@interact(\n",
    "    alpha=FloatSlider(min=-1.0, max=1.0, step=0.01, value=1.0, description='alpha'),\n",
    "    beta =FloatSlider(min=-1.0, max=1.0, step=0.01, value=1.0, description='beta')\n",
    ")\n",
    "def draw(alpha=1,beta=1):\n",
    "    fig, axes = plt.subplots(1, 4, figsize = (12, 4))\n",
    "    axes[0].imshow(np.transpose(real_batch[0].cpu(),(2,1,0)))\n",
    "    axes[0].set_title('Image 0')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(np.transpose(real_batch[1].cpu(),(2,1,0)))\n",
    "    axes[1].set_title('Image 1')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(np.transpose(real_batch[2].cpu(),(2,1,0)))\n",
    "    axes[2].set_title('Image 2')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    z_0 = netAutoEncoder.encoder(real_batch[0].unsqueeze(0))\n",
    "    z_1 = netAutoEncoder.encoder(real_batch[1].unsqueeze(0))\n",
    "    z_2 = netAutoEncoder.encoder(real_batch[2].unsqueeze(0))\n",
    "    with torch.no_grad():\n",
    "        z_3 = (z_2 + alpha*z_0 + beta*z_1)/(1+alpha+beta)\n",
    "        recon_composite = 0.5*(netAutoEncoder.decoder(z_3).squeeze()+1)\n",
    "        axes[3].imshow(np.transpose(recon_composite,(2,1,0)))\n",
    "        axes[3].set_title('Image 3')\n",
    "        axes[3].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (py314)",
   "language": "python",
   "name": "py314"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
